{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38cbcbc1-1443-42ce-89c5-ad48c9211295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f285cd-00b9-4927-821e-e5dfce5a4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='retail_etl.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a24370-301e-4b2f-b17c-882eed9e5f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ 'data/' folder already exists.\n"
     ]
    }
   ],
   "source": [
    "# Create the 'data/' folder if it doesn't exist\n",
    "data_folder = 'data/'\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "    print(\"‚úÖ 'data/' folder created. Please add CSVs inside it.\")\n",
    "else:\n",
    "    print(\"üìÅ 'data/' folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43e486f-c4a9-4b12-8849-c6802cbe9b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ 'data/' folder already exists.\n",
      "‚úÖ Raw data combined:\n",
      "  Store_ID        Date Product_ID Product_Name  Quantity_Sold  Unit_Price  \\\n",
      "0     S001  2025-07-19      P1001      Shampoo             10       150.0   \n",
      "1     S001  2025-07-19      P1002   Toothpaste              5        80.0   \n",
      "2     S001  2025-07-19      P1003         Soap             20        40.0   \n",
      "3     S001  2025-07-20      P1001      Shampoo              7       150.0   \n",
      "4     S001  2025-07-20      P1004       Lotion              3       250.0   \n",
      "\n",
      "   Discount_Percent Payment_Mode  \n",
      "0                10         Card  \n",
      "1                 5         Cash  \n",
      "2                 0          UPI  \n",
      "3                10       Wallet  \n",
      "4                15         Cash  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define folder where CSVs are stored\n",
    "data_folder = 'data/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "    print(\"‚úÖ 'data/' folder created. Add your CSV files into this folder.\")\n",
    "else:\n",
    "    print(\"üìÅ 'data/' folder already exists.\")\n",
    "\n",
    "# Combine all CSV files in the folder into a single DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"‚úÖ Raw data combined:\")\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3d6b0b-ee06-4f63-9f44-f250e017d9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available columns after normalization:\n",
      "['store_id', 'date', 'product_id', 'product_name', 'quantity_sold', 'unit_price', 'discount_percent', 'payment_mode']\n",
      "‚úÖ Transformed DataFrame:\n",
      "  store_id       date product_id product_name  quantity_sold  unit_price  \\\n",
      "0     S001 2025-07-19      P1001      Shampoo             10       150.0   \n",
      "1     S001 2025-07-19      P1002   Toothpaste              5        80.0   \n",
      "2     S001 2025-07-19      P1003         Soap             20        40.0   \n",
      "3     S001 2025-07-20      P1001      Shampoo              7       150.0   \n",
      "4     S001 2025-07-20      P1004       Lotion              3       250.0   \n",
      "\n",
      "   discount_percent payment_mode  total_sale_value sale_category  \n",
      "0                10         Card            1350.0           Low  \n",
      "1                 5         Cash             380.0           Low  \n",
      "2                 0          UPI             800.0           Low  \n",
      "3                10       Wallet             945.0           Low  \n",
      "4                15         Cash             637.5           Low  \n",
      "['store_id', 'date', 'product_id', 'product_name', 'quantity_sold', 'unit_price', 'discount_percent', 'payment_mode', 'total_sale_value', 'sale_category']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ‚úÖ Normalize column names FIRST\n",
    "combined_df.columns = [col.strip().lower().replace(' ', '_') for col in combined_df.columns]\n",
    "\n",
    "# üîç Step 1: Print available columns\n",
    "print(\"üìã Available columns after normalization:\")\n",
    "print(combined_df.columns.tolist())\n",
    "\n",
    "# ‚úÖ Step 2: Check if required columns exist before proceeding\n",
    "required_columns = ['quantity_sold', 'unit_price', 'discount_percent', 'payment_mode', 'date', 'store_id', 'product_id', 'product_name']\n",
    "\n",
    "missing_columns = [col for col in required_columns if col not in combined_df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"‚ùå Missing columns in the data: {missing_columns}\")\n",
    "else:\n",
    "    # ‚úÖ Handle missing values\n",
    "    combined_df.fillna({\n",
    "        'quantity_sold': 0,\n",
    "        'unit_price': 0.0,\n",
    "        'discount_percent': 0.0,\n",
    "        'payment_mode': 'Unknown'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # ‚úÖ Calculate total sale value\n",
    "    combined_df['total_sale_value'] = (\n",
    "        combined_df['quantity_sold'] *\n",
    "        combined_df['unit_price'] *\n",
    "        (1 - combined_df['discount_percent'] / 100)\n",
    "    )\n",
    "\n",
    "    # ‚úÖ Convert 'date' column to datetime\n",
    "    combined_df['date'] = pd.to_datetime(combined_df['date'], errors='coerce')\n",
    "\n",
    "    # ‚úÖ Drop duplicates\n",
    "    combined_df.drop_duplicates(subset=['store_id', 'date', 'product_id'], inplace=True)\n",
    "\n",
    "    # ‚úÖ Categorize sales\n",
    "    combined_df['sale_category'] = np.where(\n",
    "        combined_df['total_sale_value'] >= 10000, 'High',\n",
    "        np.where(combined_df['total_sale_value'] >= 5000, 'Medium', 'Low')\n",
    "    )\n",
    "\n",
    "    # üëÄ Preview the cleaned data\n",
    "    print(\"‚úÖ Transformed DataFrame:\")\n",
    "    print(combined_df.head())\n",
    "    print(combined_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19559afa-4537-4225-b05e-3ad82c3e334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå MySQL Error: 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    # ‚úÖ Connect to MySQL database (update credentials if needed)\n",
    "    mydb = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"root\",      # Update if you use a different password\n",
    "        database=\"retail\"     # Make sure this DB exists. Create manually if needed.\n",
    "    )\n",
    "\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    # ‚úÖ Create table if not exists\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS retail_sales (\n",
    "            store_id VARCHAR(20),\n",
    "            date DATE,\n",
    "            product_id VARCHAR(20),\n",
    "            product_name VARCHAR(100),\n",
    "            quantity_sold INT,\n",
    "            unit_price FLOAT,\n",
    "            discount_percent FLOAT,\n",
    "            payment_mode VARCHAR(20),\n",
    "            total_sale_value FLOAT,\n",
    "            sale_category VARCHAR(20),\n",
    "            PRIMARY KEY (store_id, date, product_id)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # ‚úÖ Insert each row with ON DUPLICATE KEY UPDATE (idempotent insert)\n",
    "    for _, row in combined_df.iterrows():\n",
    "        sql = \"\"\"\n",
    "            INSERT INTO retail_sales (\n",
    "                store_id, date, product_id, product_name,\n",
    "                quantity_sold, unit_price, discount_percent,\n",
    "                payment_mode, total_sale_value, sale_category\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON DUPLICATE KEY UPDATE\n",
    "                quantity_sold=VALUES(quantity_sold),\n",
    "                unit_price=VALUES(unit_price),\n",
    "                discount_percent=VALUES(discount_percent),\n",
    "                payment_mode=VALUES(payment_mode),\n",
    "                total_sale_value=VALUES(total_sale_value),\n",
    "                sale_category=VALUES(sale_category)\n",
    "        \"\"\"\n",
    "        values = (\n",
    "            row['store_id'],\n",
    "            row['date'],\n",
    "            row['product_id'],\n",
    "            row['product_name'],\n",
    "            int(row['quantity_sold']),\n",
    "            float(row['unit_price']),\n",
    "            float(row['discount_percent']),\n",
    "            row['payment_mode'],\n",
    "            float(row['total_sale_value']),\n",
    "            row['sale_category']\n",
    "        )\n",
    "        cursor.execute(sql, values)\n",
    "\n",
    "    # ‚úÖ Commit and close\n",
    "    mydb.commit()\n",
    "    cursor.close()\n",
    "    mydb.close()\n",
    "\n",
    "    print(\"‚úÖ Data loaded into MySQL successfully.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"‚ùå MySQL Error:\", err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a1fb3e-799c-4260-9c6a-cf23c236129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available columns: ['store_id', 'date', 'product_id', 'product_name', 'quantity_sold', 'unit_price', 'discount_percent', 'payment_mode', 'total_sale_value', 'sale_category']\n",
      "‚úÖ store_sales_summary.csv created.\n",
      "‚úÖ top_products.csv created.\n",
      "‚úÖ daily_sales_trend.csv created.\n"
     ]
    }
   ],
   "source": [
    "# üîç Check actual column names first\n",
    "print(\"üìã Available columns:\", combined_df.columns.tolist())\n",
    "\n",
    "# Map fallback names if store_id is missing\n",
    "fallbacks = {\n",
    "    'store_id': None,\n",
    "    'product_name': None,\n",
    "    'total_sale_value': None,\n",
    "    'date': None\n",
    "}\n",
    "\n",
    "# Try to detect correct column names dynamically\n",
    "for col in combined_df.columns:\n",
    "    if 'store' in col and 'id' in col:\n",
    "        fallbacks['store_id'] = col\n",
    "    if 'product' in col and 'name' in col:\n",
    "        fallbacks['product_name'] = col\n",
    "    if 'total_sale_value' in col:\n",
    "        fallbacks['total_sale_value'] = col\n",
    "    if col == 'date':\n",
    "        fallbacks['date'] = col\n",
    "\n",
    "# Validate all required columns found\n",
    "if None in fallbacks.values():\n",
    "    print(\"‚ùå Missing required column(s):\", [k for k, v in fallbacks.items() if v is None])\n",
    "else:\n",
    "    # ‚úÖ Total sales per store\n",
    "    store_sales = (\n",
    "        combined_df.groupby(fallbacks['store_id'])[fallbacks['total_sale_value']]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(by=fallbacks['total_sale_value'], ascending=False)\n",
    "    )\n",
    "    store_sales.to_csv('store_sales_summary.csv', index=False)\n",
    "    print(\"‚úÖ store_sales_summary.csv created.\")\n",
    "\n",
    "    # ‚úÖ Top 5 products\n",
    "    top_products = (\n",
    "        combined_df.groupby(fallbacks['product_name'])[fallbacks['total_sale_value']]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(5)\n",
    "        .reset_index()\n",
    "    )\n",
    "    top_products.to_csv('top_products.csv', index=False)\n",
    "    print(\"‚úÖ top_products.csv created.\")\n",
    "\n",
    "    # ‚úÖ Daily sales trend\n",
    "    daily_trend = (\n",
    "        combined_df.groupby([fallbacks['date'], fallbacks['store_id']])[fallbacks['total_sale_value']]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(by=fallbacks['date'])\n",
    "    )\n",
    "    daily_trend.to_csv('daily_sales_trend.csv', index=False)\n",
    "    print(\"‚úÖ daily_sales_trend.csv created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb96e2-a8fe-41be-ac2c-0ec8e575af22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
